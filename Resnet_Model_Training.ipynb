{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2d6a84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d19eb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PARAMETERS ===\n",
    "root_folder = 'aug_processed_data'  # Folder with 'healthy' and 'unhealthy' subfolders\n",
    "base_dir = 'split_data_Resnet'                   # New folder where train/val split will go\n",
    "train_ratio = 0.8                         # 80% train, 20% val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cda6708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_val_split(root_folder, base_dir, train_ratio=0.8):\n",
    "    if os.path.exists(base_dir):\n",
    "        shutil.rmtree(base_dir)  # Clean previous split if exists\n",
    "    os.makedirs(base_dir)\n",
    "\n",
    "    train_dir = os.path.join(base_dir, 'train')\n",
    "    val_dir = os.path.join(base_dir, 'val')\n",
    "\n",
    "    os.makedirs(train_dir)\n",
    "    os.makedirs(val_dir)\n",
    "\n",
    "    classes = [d for d in os.listdir(root_folder) if os.path.isdir(os.path.join(root_folder, d))]\n",
    "\n",
    "    for cls in classes:\n",
    "        os.makedirs(os.path.join(train_dir, cls))\n",
    "        os.makedirs(os.path.join(val_dir, cls))\n",
    "\n",
    "        images = os.listdir(os.path.join(root_folder, cls))\n",
    "        random.shuffle(images)\n",
    "\n",
    "        train_count = int(len(images) * train_ratio)\n",
    "        train_imgs = images[:train_count]\n",
    "        val_imgs = images[train_count:]\n",
    "\n",
    "        for img_name in train_imgs:\n",
    "            src = os.path.join(root_folder, cls, img_name)\n",
    "            dst = os.path.join(train_dir, cls, img_name)\n",
    "            shutil.copy(src, dst)\n",
    "\n",
    "        for img_name in val_imgs:\n",
    "            src = os.path.join(root_folder, cls, img_name)\n",
    "            dst = os.path.join(val_dir, cls, img_name)\n",
    "            shutil.copy(src, dst)\n",
    "\n",
    "    print(f\"‚úÖ Dataset split done! Train and val folders created at '{base_dir}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7c0fa0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset split done! Train and val folders created at 'split_data_Resnet'\n"
     ]
    }
   ],
   "source": [
    "# === Run the split function ===\n",
    "create_train_val_split(root_folder, base_dir, train_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32561e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# === 2. Setup Transfer Learning with the split folders ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder('aug_processed_data', transform=transform)\n",
    "train_dataset = datasets.ImageFolder(os.path.join(base_dir, 'train'), transform=transform)\n",
    "val_dataset = datasets.ImageFolder(os.path.join(base_dir, 'val'), transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model_resnet = models.resnet18(pretrained=True)\n",
    "for param in model_resnet.parameters():\n",
    "    param.requires_grad = False  # Freeze backbone\n",
    "\n",
    "num_features = model_resnet.fc.in_features\n",
    "model_resnet.fc = nn.Linear(num_features, len(train_dataset.classes))  # Number of classes\n",
    "\n",
    "model_resnet = model_resnet.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_resnet.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a623e843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Training loop ===\n",
    "def train_model(epochs=10):\n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        model_resnet.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model_resnet(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_acc = 100 * correct / total\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "        model_resnet.eval()\n",
    "        val_correct, val_total, val_loss = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model_resnet(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "\n",
    "        print(f\"Epoch {epoch+1} | Train Loss: {avg_loss:.4f} | Train Acc: {train_acc:.2f}% | Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    print(f\"\\nüèÜ Best Val Accuracy: {best_val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e01c9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 0.1999 | Train Acc: 95.62% | Val Loss: 0.4642 | Val Acc: 80.00%\n",
      "Epoch 2 | Train Loss: 0.1795 | Train Acc: 95.62% | Val Loss: 0.4903 | Val Acc: 82.50%\n",
      "Epoch 3 | Train Loss: 0.1915 | Train Acc: 95.62% | Val Loss: 0.5859 | Val Acc: 75.00%\n",
      "Epoch 4 | Train Loss: 0.1587 | Train Acc: 96.25% | Val Loss: 0.4872 | Val Acc: 82.50%\n",
      "Epoch 5 | Train Loss: 0.1628 | Train Acc: 98.12% | Val Loss: 0.4609 | Val Acc: 80.00%\n",
      "Epoch 6 | Train Loss: 0.1716 | Train Acc: 95.00% | Val Loss: 0.4951 | Val Acc: 82.50%\n",
      "Epoch 7 | Train Loss: 0.1619 | Train Acc: 93.75% | Val Loss: 0.5992 | Val Acc: 75.00%\n",
      "Epoch 8 | Train Loss: 0.1466 | Train Acc: 98.75% | Val Loss: 0.5216 | Val Acc: 80.00%\n",
      "Epoch 9 | Train Loss: 0.1368 | Train Acc: 98.75% | Val Loss: 0.4567 | Val Acc: 80.00%\n",
      "Epoch 10 | Train Loss: 0.1286 | Train Acc: 97.50% | Val Loss: 0.4796 | Val Acc: 82.50%\n",
      "\n",
      "üèÜ Best Val Accuracy: 82.50%\n"
     ]
    }
   ],
   "source": [
    "# === Run training ===\n",
    "train_model(epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98941da",
   "metadata": {},
   "source": [
    "Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0e5b269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_image(image_path, model, class_names):\n",
    "    model.eval()\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img_tensor = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        probs = F.softmax(output, dim=1)\n",
    "        _, predicted = torch.max(probs, 1)\n",
    "\n",
    "    print(f\"Predicted Class: {class_names[predicted.item()]}\")\n",
    "    print(f\"Class Probabilities: {probs.squeeze().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1f6e312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: series_infected_leaves_augmented\n",
      "Class Probabilities: [0.40440977 0.59559023]\n"
     ]
    }
   ],
   "source": [
    "# Assuming dataset = ImageFolder(...)\n",
    "class_names = dataset.classes  # ['healthy', 'infected']\n",
    "\n",
    "# Path to one test image\n",
    "test_image_path_1 = \"processed_data/serie infected leaves/infected_05.png\"\n",
    "\n",
    "predict_single_image(test_image_path_1, model_resnet, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77cdcf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: serie_healthy_leaves_augmented\n",
      "Class Probabilities: [0.61136645 0.38863352]\n"
     ]
    }
   ],
   "source": [
    "test_image_path_2 = \"processed_data/serie healthy leaves/healthy_05.png\"\n",
    "predict_single_image(test_image_path_2, model_resnet, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a64fe5",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33361d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Final Evaluation on Validation Set:\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "  serie_healthy_leaves_augmented       0.88      0.75      0.81        20\n",
      "series_infected_leaves_augmented       0.78      0.90      0.84        20\n",
      "\n",
      "                        accuracy                           0.82        40\n",
      "                       macro avg       0.83      0.82      0.82        40\n",
      "                    weighted avg       0.83      0.82      0.82        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_final_model():\n",
    "    model_resnet.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model_resnet(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    print(\"\\nüìä Final Evaluation on Validation Set:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=val_dataset.classes, digits=2))\n",
    "\n",
    "# Run this after training\n",
    "evaluate_final_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff0c4f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
